{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "\n",
    "# This makes the note book as wide as the screen\n",
    "#from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Funct to get the assembly of origin for a bin\n",
    "\n",
    "def bin_to_assembly(BIN):\n",
    "    '''Give a bin name and return the assembly of origin, because I wasn't thoughtful in my naming, some reformatting is \n",
    "        needed. This is also the name of the directory holding the mapping data for that assembly'''\n",
    "    \n",
    "    ## Get list of assembly directory names \n",
    "    list_assembly=os.listdir('Multimap/')\n",
    "    ## A list of sample names from the assembly names  \n",
    "    list_assembly_stripd=[ASSEMBLY.replace('-','_').replace('_pat','_Pat').replace('MH_','').split('_')[0] for ASSEMBLY in os.listdir('Multimap/')]\n",
    "    ## Zip a dictionary together of the above lists\n",
    "    dict_assembly=dict(zip(list_assembly,list_assembly_stripd))\n",
    "    \n",
    "    ## Loop over the dictionary and compare the function input bin name to return the assembly key\n",
    "    for ASSEMBLY, SAMPLE in dict_assembly.items():\n",
    "        if BIN.replace('-','_').replace('twin.','').replace('MH_','').split('_')[0] == SAMPLE:\n",
    "            return ASSEMBLY\n",
    "        \n",
    "    \n",
    "\n",
    "## Func to produce a dictionary of dataframes from the covstat files in each assembly mapping dir\n",
    "\n",
    "def covstat_to_dfdict(ASSEMBLY_DIR):\n",
    "    '''Give an assembly mapping directory and return a dictionary of dataframes for each covstat files.\n",
    "    {Keys are the name of the file: values are the dataframe}. These directiories are under the 'Multimap/' dir '''\n",
    "    \n",
    "    Multimap = os.path.expanduser(\"Multimap/\")\n",
    "    df_dict = {}\n",
    "    cov_cols=[\"#ID\",\"Avg_fold\",\"Covered_percent\" ]\n",
    "    \n",
    "    for COVSTAT in os.listdir(os.path.join(Multimap, ASSEMBLY_DIR)):\n",
    "        df_dict[COVSTAT] = pd.read_csv(os.path.join(Multimap,ASSEMBLY_DIR,COVSTAT),sep='\\t',usecols=cov_cols)\n",
    "    \n",
    "    return df_dict\n",
    "\n",
    "\n",
    "## Gets bins form the total pool of bins \n",
    "def bin_to_contigs(BIN):\n",
    "    '''For a given bin name (string), return a list of contigs that bin is made of'''\n",
    "    \n",
    "    contig_list = [record.id for record in SeqIO.parse(\"bins_dir/MH-total_bins_input/{0}\".format(BIN), \"fasta\")]\n",
    "    return contig_list\n",
    "\n",
    "\n",
    "## Dictionary of dictionaries of dataframes. Use the funciton 'covstat_to_dfdict' and collate all the dataframe \n",
    "## dictionaries together.\n",
    "## {Assembly:{assembly_covstat_name:dataframe}}\n",
    "\n",
    "list_ass_dirs=sorted(os.listdir('Multimap/'))\n",
    "list_dict_df = map(covstat_to_dfdict, list_ass_dirs)\n",
    "assembly_dict_df = dict(zip(list_ass_dirs, list_dict_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('s1_maxbin2_bins_bin.10.list', 'w') as f:\n",
    "#     for item in bin_to_contigs('s1_maxbin2_bins_bin.10.fasta'):\n",
    "#         f.write(\"%s\\n\" % item)\n",
    "\n",
    "\n",
    "# #bin_to_contigs('s1_maxbin2_bins_bin.10.fasta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Produce a dataframe of unnormalized cov values  \n",
    "\n",
    "def bin_to_avg_coverage(BIN): \n",
    "    '''Given a bin - return a list of average coverages for that bin in each sample.'''\n",
    "    \n",
    "    # Access the appropiate section of the data_frame_dict for the bin in question. \n",
    "    \n",
    "    # Returns a dictionary of covestat df's for the assembly that the bin comes from.\n",
    "    df_dict = assembly_dict_df[bin_to_assembly(BIN)]\n",
    "    #return df_dict\n",
    "     \n",
    "    # Get the list of keys to iter over\n",
    "    dict_keys = list(df_dict.keys())\n",
    "    #return dict_keys\n",
    "    \n",
    "    # Get the contigs form the bin\n",
    "    contigs = bin_to_contigs(BIN)\n",
    "    #return contigs \n",
    "    \n",
    "    # Init list to fill\n",
    "    avg_cov_list = []\n",
    "\n",
    "    for dfs in dict_keys:\n",
    "        ## loop over the dataframes\n",
    "        df = df_dict[dfs]\n",
    "        \n",
    "        \n",
    "        ## subset dataframe to 'Covered_percent' > n and average coverage is > 1 \n",
    "        n=65\n",
    "        df=df[df['Covered_percent']>n]\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Calculate avg coverage for bin while in each dataframe. \n",
    "        ## \n",
    "        avg_cov=list(df[df['#ID'].isin(contigs)].Avg_fold)\n",
    "        \n",
    "        avg_cov_list.append(np.nanmean(avg_cov))\n",
    "        \n",
    "        \n",
    "    ##list of samples     \n",
    "    samples = [sample.split('_')[0] for sample in dict_keys] \n",
    "    samples.append('Bin Id')\n",
    "    ##list of ave cov for bin in each sequenced sample, append the bin name that is being processed. \n",
    "    avg_cov_list.append(BIN)\n",
    "    \n",
    "    \n",
    "    ## Combine sample ids with coverage data for each sample\n",
    "    return dict(zip(samples, avg_cov_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/softwear/miniconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:38: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MH-s3': 9.7048,\n",
       " 'MH-s2': 7.0321,\n",
       " 'MH-s1': 6.4793,\n",
       " 'MH-Pat': 34.1108,\n",
       " 'MH-s5': nan,\n",
       " 'Bin Id': 'sr_bins.23.fasta'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_to_avg_coverage('sr_bins.23.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is where the bins are read in. \n",
    "############################################################################################################\n",
    "\n",
    "## Get list of bin names to run the  bin_to_avg_coverage function on\n",
    "\n",
    "# List of dereplicated genome bins \n",
    "bin_names = os.listdir('bins_dir/final_bins/') ## With Bac and 1 Archaea\n",
    "\n",
    "# List of all genomes bins\n",
    "Chdb = pd.read_csv(\"data_tables/Chdb.csv\", usecols=[\"Bin Id\",\"Completeness\",\"Contamination\"])\n",
    "all_bins = Chdb[\"Bin Id\"]\n",
    "\n",
    "#############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/softwear/miniconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:38: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "## Make the dataframe for output of the bin_to_avg_coverage function as list of lists\n",
    "df = pd.DataFrame([bin_to_avg_coverage(BIN) for BIN in bin_names])\n",
    "\n",
    "\n",
    "##Ignore below for now.\n",
    "\n",
    "## Do some formatting on the output df\n",
    "# Remove fasta suffix and replace 'twin.' with 'twin_' from the bin names, needed for 16s tree heatmap compatability. \n",
    "df['Bin Id']=df['Bin Id'].apply(lambda x: x.replace('.fasta','').replace('twin.','twin_'))\n",
    "# and set Bin column to index\n",
    "df = df.set_index('Bin Id')\n",
    "# Fill NaN values with 'O' place holder\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "##Ignore warning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataframe for all bins - This will take a while to compute, but it will get there\n",
    "#df_all = pd.DataFrame([bin_to_avg_coverage(BIN) for BIN in all_bins])\n",
    "\n",
    "\n",
    "#df_all.head()\n",
    "##Ignore warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_bins_complete = pd.merge(df_all, Chdb, on='Bin Id')\n",
    "#all_bins_complete.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_bins_complete.to_csv(r'all_bins_abundace_comp_score.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalization functions\n",
    "\n",
    "def col_sum(dataframe):\n",
    "    return dataframe.div(dataframe.sum(axis=0), axis=1)\n",
    "\n",
    "def log_by_n(dataframe, n ):\n",
    "    return np.log((dataframe) * n)\n",
    "\n",
    "def min_max(dataframe, n):\n",
    "     return (dataframe-dataframe.min())/(dataframe.max()-dataframe.min()) * n\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MH-Pat    1.0\n",
       "MH-s1     1.0\n",
       "MH-s2     1.0\n",
       "MH-s3     1.0\n",
       "MH-s5     1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Explore normalization of data\n",
    "\n",
    "## Show the sum of the columns \n",
    "col_sum(df).sum(axis =0)\n",
    "\n",
    "#log_by_n(col_sum(df), 10000)\n",
    "\n",
    "#log_by_n(df, 100)\n",
    "\n",
    "#col_sum(log_by_n(df, 100))\n",
    "\n",
    "#min_max(df, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Other output options\n",
    "\n",
    "#df.to_csv(r'raw.tsv', sep='\\t')\n",
    "#col_sum(df).to_csv(r'col_sum.tsv', sep='\\t')\n",
    "#log_by_n(col_sum(df), 10000).to_csv(r'col_sum-log_10000-75pc.tsv', sep='\\t')\n",
    "#log_by_n(df,100).to_csv(r'log_100.tsv',sep='\\t')\n",
    "#min_max(df,100).to_csv(r'min_max-100.tsv',sep='\\t')\n",
    "#min_max(col_sum(df),100).to_csv(r'col_sum-min_max-100',sep='\\t')\n",
    "#min_max(log_by_n(col_sum(df), 10000),100).to_csv(r'min_max-col_sum-log_10000-75pc.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export the Unnormalized abundance profile dataframe to .tsv \n",
    "#df_summed_logged.to_csv(r'abundance_bac.tsv', sep='\\t')\n",
    "\n",
    "df.to_csv(r'final_bins_abundace.tsv', sep = '\\t')\n",
    "\n",
    "#df_all.to_csv(r'all_bins_abundace.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
